\BOOKMARK [1][-]{section.1}{Introduction }{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Overview}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Elements of Reinforcement Learning}{section.1}% 3
\BOOKMARK [1][-]{section.2}{Multi-arm Bandits}{}% 4
\BOOKMARK [2][-]{subsection.2.1}{An n-Armed Bandit Problem}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.2}{Action-Value Methods}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.3}{Incremental Implementation}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.4}{Tracking a Nonstationary Problem}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.5}{Optimistic Initial Values}{section.2}% 9
\BOOKMARK [2][-]{subsection.2.6}{Upper-confidence-bound Action Selection}{section.2}% 10
\BOOKMARK [2][-]{subsection.2.7}{Associative Search \(Contextual Bandits\)}{section.2}% 11
\BOOKMARK [2][-]{subsection.2.8}{Key Takeaways}{section.2}% 12
\BOOKMARK [2][-]{subsection.2.9}{Exercises}{section.2}% 13
\BOOKMARK [3][-]{subsubsection.2.9.1}{Exercise 2.1}{subsection.2.9}% 14
\BOOKMARK [3][-]{subsubsection.2.9.2}{Exercise 2.2}{subsection.2.9}% 15
\BOOKMARK [3][-]{subsubsection.2.9.3}{Exercise 2.3}{subsection.2.9}% 16
\BOOKMARK [3][-]{subsubsection.2.9.4}{Exercise 2.4}{subsection.2.9}% 17
\BOOKMARK [3][-]{subsubsection.2.9.5}{Exercise 2.5}{subsection.2.9}% 18
\BOOKMARK [3][-]{subsubsection.2.9.6}{Exercise 2.6}{subsection.2.9}% 19
\BOOKMARK [3][-]{subsubsection.2.9.7}{Exercise 2.7}{subsection.2.9}% 20
\BOOKMARK [3][-]{subsubsection.2.9.8}{Exercise 2.8}{subsection.2.9}% 21
\BOOKMARK [3][-]{subsubsection.2.9.9}{Exercise 2.9}{subsection.2.9}% 22
\BOOKMARK [3][-]{subsubsection.2.9.10}{Exercise 2.10}{subsection.2.9}% 23
\BOOKMARK [1][-]{section.3}{Finite Markov Decision Processes}{}% 24
\BOOKMARK [2][-]{subsection.3.1}{The Agent-Environment Interface}{section.3}% 25
\BOOKMARK [2][-]{subsection.3.2}{Goals and Rewards}{section.3}% 26
\BOOKMARK [2][-]{subsection.3.3}{Returns and Episodes}{section.3}% 27
\BOOKMARK [2][-]{subsection.3.4}{Unified Notation for Episodic and Continuing Tasks}{section.3}% 28
\BOOKMARK [2][-]{subsection.3.5}{The Markov Property}{section.3}% 29
\BOOKMARK [2][-]{subsection.3.6}{Markov Decision Process \(MDP\)}{section.3}% 30
\BOOKMARK [2][-]{subsection.3.7}{Policies and Value Functions}{section.3}% 31
\BOOKMARK [2][-]{subsection.3.8}{Optimal Policies and Value Functions}{section.3}% 32
\BOOKMARK [2][-]{subsection.3.9}{Optimality and Approximation}{section.3}% 33
\BOOKMARK [2][-]{subsection.3.10}{Key Takeaways}{section.3}% 34
\BOOKMARK [2][-]{subsection.3.11}{Exercises}{section.3}% 35
\BOOKMARK [3][-]{subsubsection.3.11.1}{Exercise 3.1}{subsection.3.11}% 36
\BOOKMARK [3][-]{subsubsection.3.11.2}{Exercise 3.2}{subsection.3.11}% 37
\BOOKMARK [3][-]{subsubsection.3.11.3}{Exercise 3.3}{subsection.3.11}% 38
\BOOKMARK [3][-]{subsubsection.3.11.4}{Exercise 3.4}{subsection.3.11}% 39
\BOOKMARK [3][-]{subsubsection.3.11.5}{Exercise 3.5}{subsection.3.11}% 40
\BOOKMARK [3][-]{subsubsection.3.11.6}{Exercise 3.6}{subsection.3.11}% 41
\BOOKMARK [3][-]{subsubsection.3.11.7}{Exercise 3.7}{subsection.3.11}% 42
\BOOKMARK [3][-]{subsubsection.3.11.8}{Exercise 3.8}{subsection.3.11}% 43
\BOOKMARK [3][-]{subsubsection.3.11.9}{Exercise 3.9}{subsection.3.11}% 44
\BOOKMARK [3][-]{subsubsection.3.11.10}{Exercise 3.10}{subsection.3.11}% 45
\BOOKMARK [3][-]{subsubsection.3.11.11}{Exercise 3.11}{subsection.3.11}% 46
\BOOKMARK [3][-]{subsubsection.3.11.12}{Exercise 3.12}{subsection.3.11}% 47
\BOOKMARK [3][-]{subsubsection.3.11.13}{Exercise 3.13}{subsection.3.11}% 48
\BOOKMARK [3][-]{subsubsection.3.11.14}{Exercise 3.14}{subsection.3.11}% 49
\BOOKMARK [3][-]{subsubsection.3.11.15}{Exercise 3.15}{subsection.3.11}% 50
\BOOKMARK [3][-]{subsubsection.3.11.16}{Exercise 3.16}{subsection.3.11}% 51
\BOOKMARK [3][-]{subsubsection.3.11.17}{Exercise 3.17}{subsection.3.11}% 52
\BOOKMARK [3][-]{subsubsection.3.11.18}{Exercise 3.18}{subsection.3.11}% 53
\BOOKMARK [3][-]{subsubsection.3.11.19}{Exercise 3.19}{subsection.3.11}% 54
\BOOKMARK [3][-]{subsubsection.3.11.20}{Exercise 3.20}{subsection.3.11}% 55
\BOOKMARK [3][-]{subsubsection.3.11.21}{Exercise 3.21}{subsection.3.11}% 56
\BOOKMARK [3][-]{subsubsection.3.11.22}{Exercise 3.22}{subsection.3.11}% 57
\BOOKMARK [3][-]{subsubsection.3.11.23}{Exercise 3.23}{subsection.3.11}% 58
\BOOKMARK [3][-]{subsubsection.3.11.24}{Exercise 3.24}{subsection.3.11}% 59
\BOOKMARK [3][-]{subsubsection.3.11.25}{Exercise 3.25}{subsection.3.11}% 60
\BOOKMARK [3][-]{subsubsection.3.11.26}{Exercise 3.26}{subsection.3.11}% 61
\BOOKMARK [3][-]{subsubsection.3.11.27}{Exercise 3.27}{subsection.3.11}% 62
\BOOKMARK [3][-]{subsubsection.3.11.28}{Exercise 3.28}{subsection.3.11}% 63
\BOOKMARK [3][-]{subsubsection.3.11.29}{Exercise 3.29}{subsection.3.11}% 64
